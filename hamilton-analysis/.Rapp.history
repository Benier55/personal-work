y
y <- 6:9
y == 8
x * y
x/y
x <- matrix(1:4, 2,2); y <- matrix(rep(10,4),2,2)
x
y
?rep
x*y
x/y
x %*% y
install.packages("swirl")
swirl()
lapply
x <- list(a=1:5, b=rnorm(10))
lapply(x,mean)
a
x
x <- list(a=1:4,b=rnorm(10),c=rnorm(20,1),d=rnorm(100,5))
lapply(x,mean)
x <- 1:4
lapply(x,runif)
lapply(x,runif, min=0,max=10)
x<- list(a=matrix(1:4,2,2),b=matrix(1:6,3,2))
x
lapply(x,function(elt) elt[,1])
elt
lapply(x,function(elt) elt[1,])
str(apply)
x <- matrix(rmorm(200),20,10)
x <- matrix(rnorm(200),20,10)
apply(x,2,mean)
apply(x,1,sum)
x
colMeans
a <- array(rnorm(2*2*10),c(2,2,10))
a
apply(a,c(1,2),mean)
rowMeans(a,dims=2)
mapply(rep1:4,4:1)
mapply(rep,1:4,4:1)
list(rep(1,4),rep(2,3),rep(3,2),rep(4,1))
x <- c(rnorm(10),runif(10),rnorm(10,1))
f<-gl(3,10)
f
tapply(x,f,mean)
tapply(x,f,mean, simplify=FALSE)
tapply(x,f,range)
x <- c(rnorm(10),runif(10),rnorm(10,1))
f<-gl(3,10)
split(x,f)
f
lapply(split(x,f),mean)
tapply(x,f,mean)
library(datasets)
head(airquality)
s <- split(airquality, airquality$Month)
s
lapply(s,function(x),colMeans(x[,c("Ozone","Soler.R","Wind")])
lapply(s,function(x),colMeans(x[,c("Ozone","Solar.R","Wind")]))
lapply(s,function(x),colMeans(x[, c("Ozone","Solar.R","Wind")]))
lapply(s,function(x) colMeans(x[, c("Ozone","Solar.R","Wind")]))
sapply(s, function(x) colMeans(x[,c("Ozone","Solar.R","Wind")]))
sapply(s, function(x) colMeans(x[,c("Ozone","Solar.R","Wind")], na.rm=TRUE))
x <- rnorm(10)
f1<- gl(2,5)
f2<-gl(5,2)
f1
f2
interactions(f1,f2)
interaction(f1,f2)
split(x,list(f1,f2),drop=TRUE)
split(x,list(f1,f2))
log(-1)
makeVector <- function(x = numeric()) {#
        m <- NULL#
        set <- function(y) {#
                x <<- y#
                m <<- NULL#
        }#
        get <- function() x#
        setmean <- function(mean) m <<- mean#
        getmean <- function() m#
        list(set = set, get = get,#
             setmean = setmean,#
             getmean = getmean)#
}
makeVector(3)
x
cachemean <- function(x, ...) {#
        m <- x$getmean()#
        if(!is.null(m)) {#
                message("getting cached data")#
                return(m)#
        }#
        data <- x$get()#
        m <- mean(data, ...)#
        x$setmean(m)#
        m#
}
cachemean(3)
cachemean(x)
x
matrix(10,2,2)
x<- matrix(10,2,2)
solve(X)
solve(x
)
library(choroplethr)#
library(choroplethrMaps)#
#
data(df_president_ts)#
?df_president_ts#
#
df_president_ts[1:8, 1:4]
head(df_president_ts)
pres <- df_president_ts
head(pres)
pres$value = pres$"2012"
state_choropleth(pres,num_colors=2,title="2012 Presidential Election Map")
pres$value = pres$"1860"
state_choropleth(pres,num_colors=2,title="1860 Presidential Election Map")
state_choropleth(pres,num_colors=4,title="1860 Presidential Election Map")
?state_choropleth
library(acs)
api.key.install(86ab434a64e30b585e4705a5e823b69064ff4b8c)
api.key.install(<86ab434a64e30b585e4705a5e823b69064ff4b8c>)
api.key.install(86ab434a64e30b585e4705a5e823b69064ff4b8c)
?api.key.install
api.key.install(86ab434a64e30b585e4705a5e823b69064ff4b8c)
api.key.install("86ab434a64e30b585e4705a5e823b69064ff4b8c")
library(choroplethr)
?get_state_demographics
df_2010_demographics = get_state_demographics(2010)
df_2010_demographics$value = df_2010_demographics$total_population
state_choropleth(df_2010_demographics, #
#
title = “2010 State Population Estimates”, #
#
legend = “Population”)
state_choropleth(df_2010_demographics, title = "2010 State Population Estimates", legend = "Population")
makeCacheMatrix <- function(x = matrix()) {#
		i <- NULL#
		set <- function(y) {#
				x <<- y#
				i <<- NULL#
		}#
		get <- function() x#
		setinverse <- function(inverse) i <<- inverse#
		getinverse <- function() i#
		list (set = set, get = get, #
			setinverse = setinverse,#
			getinverse = getinverse) #
}
cacheSolve <- function(x, ...) {#
        i <- x$solve()#
        if(!is.null(i)) {#
                message("getting cached data")#
                return(i)#
        }#
        data <- x$get()#
        m <- solve(data, ...)#
        x$setinverse(i)#
        i#
}
A <- matrix(1:4, 2, 2)
a1 <- makeCacheMatrix(A)#
A.inv <- cacheSolve(a1)
A$get()
a1$get()
a1$set(matrix(2:5,2,2))
a1$get()
a1
solve(matrix(2:5,2,2))
a1$get()
a1$getinverse()
a1$setinverse(10)
a1$getinverse()
a1$setinverse(matrix(1:4,2,2))
a1$getinverse()
a1$setinverse(NULL)
a1$getinverse()
is.null(a1$getinverse())
!is.null(a1$getinverse())
A
A$solve()
a1$solve()
cacheSolve <- function(x, ...) {#
        i <- x$getinverse()#
        if(!is.null(i)) {#
                message("getting cached data")#
                return(i)#
        }#
        data <- x$get()#
        m <- solve(data, ...)#
        x$setinverse(i)#
        i#
}
a1 <- makeCacheMatrix(A)#
A.inv <- cacheSolve(a1)
A.inv
a1
A
solve(A)
cacheSolve(a1)
A$get()
a1$get()
d <- a1$get()
solve(d)
n <- solve(d)
i
cacheSolve <- function(x, ...) {#
        i <- x$getinverse()#
        if(!is.null(i)) {#
                message("getting cached data")#
                return(i)#
        }#
        data <- x$get()#
        i <- solve(data, ...)#
        x$setinverse(i)#
        i#
}
a1 <- makeCacheMatrix(A)#
A.inv <- cacheSolve(a1)
A.inv
solve(A)
a <- makeCacheMatrix(c(1,2,3,4))
b <- makeCacheMatrix(c(3,2,1,1,1,-1,0,1,2))
cacheSolve(a)
a
a <- makeCacheMatrix(matrix(1:4,2,2))
b <- makeCacheMatrix(matrix(c(3,2,1,1,1,-1,0,1,2),3,3))
cacheSolve(a)
cacheSolve(b)
cacheSolve(a)
cacheSolve(a1)
library(datasets)#
data(iris)
?IRIS
?iris
head(iris)
?colMeans
a <- subset(iris, Species == virginica, select = Sepal.Length)
iris
a <- subset(iris, Species == virginica, select = Sepal.Length)
a <- subset(iris, Species = virginica, select = Sepal.Length)
a
a <- subset(iris, Species == virginica, select = Sepal.Length)
a <- subset(iris, Species == "virginica", select = Sepal.Length)
a
colMeans(a)
head(iris)
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
colMeans(iris, Sepal.Length)
colMeans(iris$Sepal.Length)
colMeans(iris[,1]
)
colMeans(iris)
iris$Sepal.Length
colMeans(iris, dims=2)
colMeans(iris, dims=  2L)
b <- iris$Sepal.Length
mean(b)
library(datasets)#
data(mtcars)
head(mtcars)
?sapply
apply(mtcars, 2, mean)
with(mtcars, tapply(mpg, cyl, mean))
?with
with(mtcars, tapply(hp, cyl, mean))
with(mtcars, tapply(hp, cyl, mean))[1]
a <- with(mtcars, tapply(hp, cyl, mean))
a[1]-a[3]
debug(ls)
ls
?ls
ls
debug(ls)
ls
?ls
ls
debug(ls)
ls
?debug
x <- c(-.5,0,1,1,1.5)
y <- c(0,0,2,0,0)
pbeta(.75,2,1)
?pbeta
pbeta(.4,2,1)
pbeta(.5,2,1)
pbeta(.6,2,1)
pbeta(c(.4,.5,.6),2,1)
qbeta(.5,2,1)
qbeta(.5,3,1)
qbeta(50,3,1)
setwd("~/GitHub/personal-work/hamilton-analysis")
library(tm)
setwd("cmeans") ## Set the working directory to the "cmeans" folder.#
wd <- getwd() ## Store this working directory.#
docs <- Corpus(DirSource(getwd())) ## Define our corpus as all the text files in the "cmeans" folder.
docs <- tm_map(docs, content_transformer(tolower))#
docs <- tm_map(docs, removePunctuation)#
docs <- tm_map(docs, removeNumbers)#
docs <- tm_map(docs, removeWords, stopwords("english"))#
docs <- tm_map(docs, removeWords, "applause")#
docs <- tm_map(docs, stemDocument, language = "english")
#x11()
tdm <- TermDocumentMatrix(docs)
colnames(tdm) <- c("Angelica Schuyler", "Aaron Burr", "Elizabeth Schuyler", "Ensemble", "Extras", "King George", "Alexander Hamilton", "Thomas Jefferson", "LaFayette", "John Laurens", "James Madison", "Hercules Mulligan", "Philip Hamilton", "George Washington")
tdm_sparse <- removeSparseTerms(tdm, .7)
c_means <- cmeans(t(tdm_sparse), 3)
library(e1071)
c_means <- cmeans(t(tdm_sparse), 3)
c_means$membership
write.csv(t(c_means$membership), "cmeansmembers.csv")
?t
write.csv(t(c_means$centers), "cmeanscenters.csv")
write.csv(c_means$membership, "csvs/cmeansmembers.csv")
docs <- Corpus(DirSource(getwd()))
docs <- tm_map(docs, content_transformer(tolower))#
docs <- tm_map(docs, removePunctuation)#
docs <- tm_map(docs, removeNumbers)#
docs <- tm_map(docs, removeWords, stopwords("english"))#
docs <- tm_map(docs, removeWords, "applause")#
docs <- tm_map(docs, stemDocument, language = "english")
tdm <- TermDocumentMatrix(docs) ## Convert the data into a matrix.#
colnames(tdm) <- c("Angelica Schuyler", "Aaron Burr", "Elizabeth Schuyler", "Ensemble", "Extras", "King George", "Alexander Hamilton", "Thomas Jefferson", "LaFayette", "John Laurens", "James Madison", "Hercules Mulligan", "Philip Hamilton", "George Washington") ## Label the columns with character names.#
tdm_sparse <- removeSparseTerms(tdm, .7) ## Remove sparse terms. The .7 parameter here is a judgment call, feel free to experiment with different values.
class(tdm)
tdm
ncol(tdm)
head(tdm)
tdm$!
tdm$1
tdm[1]
tdm$TermDocumentMatrix
tdm$simple_triplet_matrix
docs <- Corpus(DirSource(getwd())) ## Define our corpus as all the text files in the "cmeans" folder.#
#
## Process the data: get it lower case, remove punctuation, remove numbers and common words #
docs <- tm_map(docs, content_transformer(tolower))#
docs <- tm_map(docs, removePunctuation)#
docs <- tm_map(docs, removeNumbers)#
docs <- tm_map(docs, removeWords, stopwords("english"))#
docs <- tm_map(docs, removeWords, "applause")#
docs <- tm_map(docs, stemDocument, language = "english")#
#
## More processing.#
tdm <- TermDocumentMatrix(docs) ## Convert the data into a matrix.#
colnames(tdm) <- c("Angelica Schuyler", "Aaron Burr", "Elizabeth Schuyler", "Ensemble", "Extras", "King George", "Alexander Hamilton", "Thomas Jefferson", "LaFayette", "John Laurens", "James Madison", "Hercules Mulligan", "Philip Hamilton", "George Washington")
setwd(..)
setwd("..")
